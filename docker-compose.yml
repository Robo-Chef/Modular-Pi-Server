# Main Docker Compose file for Raspberry Pi Home Server
# This file includes all services in one place for easy management

version: "3.8"

services:
  # Core DNS Services
  pihole:
    image: pihole/pihole:latest
    container_name: pihole
    hostname: ${PIHOLE_HOSTNAME:-my-pihole.local}
    networks:
      pihole_net:
        ipv4_address: 172.20.0.3
      isolated_net: # Block outbound DNS
    volumes:
      - ./docker/pihole/etc-pihole:/etc/pihole
      - ./docker/pihole/etc-dnsmasq.d:/etc/dnsmasq.d
      - ./docker/pihole/logs:/var/log/pihole
    environment:
      TZ: ${TZ:-America/New_York}
      WEBPASSWORD: ${PIHOLE_PASSWORD}
      DNS1: 172.20.0.2#5053 # Unbound
      DNS2: 127.0.0.1#5053 # Fallback to Unbound
      VIRTUAL_HOST: ${PIHOLE_HOSTNAME:-my-pihole.local}
      VIRTUAL_PORT: 80
      ServerIP: ${PI_STATIC_IP:-192.168.1.XXX}
      PIHOLE_DNS_: 172.20.0.2#5053
      PIHOLE_INTERFACE: eth0
      FTLCONF_LOCAL_IPV4: 172.20.0.3
    ports:
      - "53:53/tcp"
      - "53:53/udp"
      - "80:80/tcp"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 512M
        reservations:
          memory: 256M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/admin/api.php?summary"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    dns:
      - 172.20.0.2
      - 127.0.0.1

  unbound:
    image: klutchell/unbound:latest
    container_name: unbound
    hostname: unbound-server
    networks:
      pihole_net:
        ipv4_address: 172.20.0.2
    volumes:
      - ./docker/unbound/config:/etc/unbound/custom
      - ./docker/unbound/logs:/var/log/unbound
    environment:
      TZ: ${TZ:-America/New_York}
    ports:
      - "127.0.0.1:5053:5053/tcp"
      - "127.0.0.1:5053:5053/udp"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 256M
        reservations:
          memory: 128M
    healthcheck:
      test: ["CMD", "unbound-control", "status"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    command: -d -v

  # Monitoring Services
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    hostname: prometheus-server
    networks:
      - monitoring_net
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./monitoring/prometheus/rules:/etc/prometheus/rules
      - prometheus_data:/prometheus
    environment:
      TZ: ${TZ:-America/New_York}
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.console.libraries=/etc/prometheus/console_libraries"
      - "--web.console.templates=/etc/prometheus/consoles"
      - "--storage.tsdb.retention.time=${PROMETHEUS_RETENTION:-15d}"
      - "--web.enable-lifecycle"
      - "--web.enable-admin-api"
    ports:
      - "127.0.0.1:9090:9090"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
        reservations:
          memory: 256M
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--quiet",
          "--tries=1",
          "--spider",
          "http://localhost:9090/-/healthy",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    hostname: grafana-server
    networks:
      - monitoring_net
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
    environment:
      TZ: ${TZ:-America/New_York}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD}
      GF_USERS_ALLOW_SIGN_UP: false
      GF_USERS_ALLOW_ORG_CREATE: false
      GF_SECURITY_DISABLE_GRAVATAR: true
      GF_ANALYTICS_REPORTING_ENABLED: false
      GF_ANALYTICS_CHECK_FOR_UPDATES: false
      GF_LOG_LEVEL: warn
      GF_DATABASE_TYPE: sqlite3
      GF_SESSION_PROVIDER: file
      GF_SESSION_PROVIDER_CONFIG: sessions
    ports:
      - "3000:3000"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
        reservations:
          memory: 256M
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget --quiet --tries=1 --spider http://localhost:3000/api/health || exit 1",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    depends_on:
      - prometheus

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    hostname: node-exporter
    networks:
      - monitoring_net
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - "--path.procfs=/host/proc"
      - "--path.rootfs=/rootfs"
      - "--path.sysfs=/host/sys"
      - "--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)"
    ports:
      - "127.0.0.1:9100:9100"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "0.1"
          memory: 128M
        reservations:
          memory: 64M

  uptime-kuma:
    image: louislam/uptime-kuma:latest
    container_name: uptime-kuma
    hostname: uptime-kuma-server
    networks:
      - monitoring_net
    volumes:
      - uptime_kuma_data:/app/data
    environment:
      TZ: ${TZ:-America/New_York}
    ports:
      - "3001:3001"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "0.3"
          memory: 256M
        reservations:
          memory: 128M
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--quiet",
          "--tries=1",
          "--spider",
          "http://localhost:3001",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Optional Services (uncomment to enable)
  # homeassistant:
  #   image: ghcr.io/home-assistant/home-assistant:stable
  #   container_name: homeassistant
  #   hostname: homeassistant-server
  #   networks:
  #     - smart_home_net
  #   volumes:
  #     - homeassistant_data:/config
  #     - /etc/localtime:/etc/localtime:ro
  #   environment:
  #     TZ: ${TZ:-America/New_York} # Changed default timezone
  #     PUID: 1000
  #     PGID: 1000
  #   ports:
  #     - "8123:8123"
  #   restart: unless-stopped
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: "1.0"
  #         memory: 1G
  #       reservations:
  #         memory: 512M
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:8123"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 60s

  # gitea:
  #   image: gitea/gitea:latest
  #   container_name: gitea
  #   hostname: gitea-server
  #   networks:
  #     - dev_net
  #   volumes:
  #     - gitea_data:/data
  #     - /etc/timezone:/etc/timezone:ro
  #     - /etc/localtime:/etc/localtime:ro
  #   environment:
  #     TZ: ${TZ:-America/New_York} # Changed default timezone
  #     USER_UID: 1000
  #     USER_GID: 1000
  #     GITEA__database__DB_TYPE: sqlite3
  #     GITEA__database__PATH: /data/gitea/gitea.db
  #     GITEA__server__DOMAIN: gitea.local
  #     GITEA__server__ROOT_URL: http://gitea.local:3002
  #     GITEA__server__SSH_DOMAIN: gitea.local
  #     GITEA__server__SSH_PORT: 2222
  #     GITEA__server__HTTP_PORT: 3000
  #     GITEA__server__PROTOCOL: http
  #     GITEA__security__INSTALL_LOCK: true
  #     GITEA__service__DISABLE_REGISTRATION: false
  #     GITEA__service__REQUIRE_SIGNIN_VIEW: false
  #     GITEA__log__LEVEL: Info
  #     GITEA__log__ROOT_PATH: /data/gitea/log
  #   ports:
  #     - "3002:3000"
  #     - "2222:22"
  #   restart: unless-stopped
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: "0.5"
  #         memory: 512M
  #       reservations:
  #         memory: 256M
  #   healthcheck:
  #     test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 30s

volumes:
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  uptime_kuma_data:
    driver: local
  # homeassistant_data:
  #   driver: local
  # gitea_data:
  #   driver: local

networks:
  pihole_net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/24
          gateway: 172.20.0.1
    internal: false
  monitoring_net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.21.0.0/24
          gateway: 172.21.0.1
  isolated_net:
    driver: bridge
    internal: true
  # smart_home_net:
  #   driver: bridge
  #   ipam:
  #     config:
  #       - subnet: 172.22.0.0/24
  #         gateway: 172.22.0.1
  # dev_net:
  #   driver: bridge
  #   ipam:
  #     config:
  #       - subnet: 172.23.0.0/24
  #         gateway: 172.23.0.1
